\input templates/header
\title[ASD - Approssimazione]{\textbf{Algoritmi e Strutture Dati}\\[24pt]Tecniche risolutive per problemi intrattabili}

\usepackage{epigraph}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{pdfpages}

\newcommand{\PTIME}{\mbox{\sc $\mathbb{P}$}}
\renewcommand{\NP}{\mbox{$\mathbb{NP}$}}
\newcommand{\TIME}{\mbox{$\mathbb{TIME}$}}
\newcommand{\EXPTIME}{\mbox{$\mathbb{EXPTIME}$}}
\newcommand{\SPACE}{\mbox{$\mathbb{SPACE}$}}
\newcommand{\PSPACE}{\mbox{$\mathbb{PSPACE}$}}

\newcommand{\R}[1]{\textcolor{red}{#1}}
\newcommand{\B}[1]{\textcolor{blue}{#1}}

\newcommand{\Missing}{\mathit{missing}}
\newcommand{\DP}{\mathit{DP}}
\newcommand{\Cost}{\mathit{cost}}
\newcommand{\Transfer}{\mathit{transfer}}
%\newcommand{\Out}{\mathit{out}}
%\newcommand{\Back}{\mathit{back}}



\renewcommand{\arraystretch}{1.4}
\graphicspath{{figs/19/}}
\renewcommand{\enumerazione}{\fontproc{enumeration}}
\newcommand{\isAdmissible}{\fontproc{isAdmissible}}
\newcommand{\isImpossible}{\fontproc{reject}}

\begin{document}

%-------------------------------------------------------------------------
\FrameTitle{}

%-------------------------------------------------------------------------
\begin{PlainFrame}{Sommario}
\TwoCols{
  \tableofcontents
}{
 \epigraph{Chi si accontenta, gode}{Proverbio}

 \bigskip
 \epigraph{Le mieux est l’ennemi du bien\\Il meglio è nemico del bene}{Voltaire, La Bégueule, 1772}
  
}
\end{PlainFrame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduzione}


%-------------------------------------------------------------------------
\begin{frame}{Introduzione}


Non si può avere tutto dalla vita; bisogna rinunciare a qualcosa:

\smallskip
\BIL
\item \B{Generalità}: 
  \BI
  \item Algoritmi \alert{pseudo-polinomiali} che sono efficienti
    solo per alcuni casi particolari dell'input
  \EI
\item \B{Ottimalità}: 
  \BI
  \item Algoritmi di \alert{approssimazione}, che garantiscono di ottenere soluzioni "vicine" alla soluzione ottimale
  \EI
\item \B{Formalità}: 
  \BI
  \item Algoritmi \alert{euristici}, di solito basati su tecniche greedy o di ricerca locale, che forniscano sperimentalmente risultati buoni
  \EI
\item \B{Efficienza}:
  \BI
  \item Algoritmi esponenziali \alert{branch-\&-bound}, che limitano lo spazio di ricerca con un'accurata potatura
  \EI
\EIL

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algoritmi pseudo-polinomiali}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-------------------------------------------------------------------------
\begin{frame}{Esempio: Subset-Sum}

\vspace{-9pt}
\begin{myboxtitle}[Somma di sottoinsieme (\textsc{subset-sum})]
Dati un vettore $A$ contenente $n$ interi positivi ed un intero positivo $k$, \alert{esiste} un sottoinsieme $S \subseteq \{ 1 \ldots n\}$ tale che 
$\displaystyle \sum_{i \in S} a[i] = k$?
\end{myboxtitle}

\begin{overprint}
\onslide<1|handout:0>
\TwoColsCustom{0.63}{0.34}{
\vspace{-12pt}
\IG{1.0}{subsetsum.png}
}{
\footnotesize
\url{https://xkcd.com/287/}
}
\onslide<2|handout:1>
\BIL
\item Utilizzando \alert{backtracking}, abbiamo risolto la \alert{versione di ricerca} di questo problema
\item Quella appena enunciata è la \alert{versione decisionale}
\item Per semplificare il confronto, ci concentriamo sulla seconda
\EIL
\end{overprint}

\end{frame}



%-------------------------------------------------------------------------
\begin{frame}{Subset Sum -- Programmazione Dinamica}

Definiamo una tabella booleana $DP[0 \ldots n][0 \ldots k]$. 

\medskip
$\DP[i][r]$ è uguale a \TRUE se esiste un sottoinsieme dei primi $i$ valori memorizzati in $A$ la cui somma è pari a $r$, \FALSE altrimenti.

\begin{overprint}
\onslide<1|handout:0>
\[
\DP[i][r] = \begin{cases}
  \phantom{\TRUE} & r = 0 \\
  \phantom{\FALSE} & r > 0 \wedge i=0 \\
  \phantom{\DP[i-1][r]}\ & r>0 \wedge i>0 \wedge A[i] > r \\
  \phantom{\DP[i-1][r]\ \OR\ \DP[i-1][r-A[i]]} & r>0 \wedge i>0 \wedge A[i] \leq r \\
\end{cases}
\]

\onslide<2|handout:1>
\[
\DP[i][r] = \begin{cases}
  \TRUE & r = 0 \\
  \FALSE & r > 0 \wedge i=0 \\
  \DP[i-1][r]\ & r>0 \wedge i>0 \wedge A[i] > r \\
  \DP[i-1][r]\ \OR\ \DP[i-1][r-A[i]] & r>0 \wedge i>0 \wedge A[i] \leq r
\end{cases}
\]
\end{overprint}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Subset Sum -- Programmazione dinamica -- $\Theta(nk)$}

\vspace{-9pt}
\begin{Procedure}
\caption[A]{\BOOLEAN \fontproc{subsetSum}($\INTARRAY\ A,\ \INTEGER\ n,\ \INTEGER\ k$)}
$\BOOLEAN[\,][\,]\ \DP = \NEW\ \BOOLEAN[0 \ldots n][0 \ldots k] = \{ \FALSE \}$\;
\For{$i=0$ \TO\ $n$}{
  $\DP[i][0] = \TRUE$\REMR{$r=0$}
}
\For{$r=1$ \TO\ $k$}{
  $\DP[0][r] = \FALSE$\REMR{$r>0 \wedge i=0$}
}
\For{$i=1$ \TO\ $n$}{
  \For{$r=1$ \TO $A[i]-1$}{
    $\DP[i][r] = \DP[i-1][r]$\REMR{$A[i]>r$}
  }
  \For{$r=A[i]$ \TO $k$}{
    $\DP[i][r] = \DP[i-1][r]\ \OR\ \DP[i-1][r-A[i]]$\REMR{$A[i] \leq r$}
  }
}
\Return $\DP[n][k]$\;
\end{Procedure}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Subset Sum -- Programmazione dinamica -- $\Theta(nk)$}

\vspace{-9pt}
\begin{myboxtitle}[Esempio]
\vspace{-12pt}
\begin{align*}
A &= [5,9,10]\\
n &=3\\ 
k &=24
\end{align*} 
\end{myboxtitle}

\IG{1.0}{table-dp.pdf}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Subset Sum -- Backtracking -- $O(2^n)$}

\vspace{-9pt}
\begin{Procedure}
\caption[A]{\BOOLEAN \fontproc{ssRec}($\INTARRAY\ A,\ \INTEGER\ i,\ \INTEGER\ r$)}

\uIf{$r \Eq 0$}{
  \Return \TRUE\;
}
\uElseIf{$i \Eq 0$}{
  \Return \FALSE\;
}
\uElseIf{$A[i]>r$}{
  \Return $\fontproc{ssRec}(A,i-1,r)$\;
}
\Else{
  \Return $\fontproc{ssRec}(A,i-1,r)\ \OR\ \fontproc{ssRec}(A,i-1,r-A[i])$\;
}
\end{Procedure}

\vspace{-9pt}
\IG{1.0}{table-memo.pdf}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Subset Sum -- Memoization -- $O(nk)$}

\vspace{-9pt}
\begin{Procedure}
\caption[A]{\BOOLEAN \fontproc{ssRec}($\INTARRAY\ A,\ \INTEGER\ i,\ \INTEGER\ r, \alert{\Dictionary\ \DP}$)}

\uIf{$r \Eq 0$}{
  \Return \TRUE\;
}
\uElseIf{$r<0$ \OR\ $i \Eq 0$}{
  \Return \FALSE\;
}
\alert{
\Else{
 \BOOLEAN $\mathit{res} = \DP.\dictlookup((i,r))$\;
  \If{$\mathit{res} \Eq \Nil$}{
    $\mathit{res} = \fontproc{ssRec}(A,i-1,r,\DP)$\;
    \If{$A[i]<r$}{
      $\mathit{res} = \mathit{res}$ \OR\ $\fontproc{ssRec}(A,i-1,r-A[i],\DP)$\;
    }
    $\DP.\dictinsert((i,r), \mathit{res})$\;
  }
  \Return $\mathit{res}$\;
}
}
\end{Procedure}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Subset Sum -- Memoization -- $O(nk)$}

\vspace{-9pt}
\IG{1.0}{table-memo.pdf}

\begin{myboxtitle}[Esempio]
\TwoCols{
\begin{align*}
A &= [1,1,1,1,1]\\
n &= 5\\ 
k &= 5
\end{align*} 
}{
\vspace{-6pt}
\IG{1.0}{table-limite.pdf}
}
\end{myboxtitle}



\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Complessità -- Riassunto}

\vspace{-9pt}
\BB{
\begin{tabular}{ll}
Programmazione dinamica & $\Theta(nk)$ \\
Backtracking & $O(2^n)$ \\
Memoization con dizionario & $O(nk), O(2^n)$\\
\end{tabular}
}

\BB{Dynamic Programming, Memoization $\equiv$ "Careful brute force"
\medskip
\begin{flushright}
Erik Demeine
\end{flushright}
}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Complessità -- Discussione}

\vspace{-9pt}
\BB{
$O(nk)$ è una complessità polinomiale?
}
\pause
\medskip
\BIL
\item No, $k$ è parte dell'input, non una dimensione dell'input
\item $k$ viene rappresentato da $t = \lceil \log k \rceil$ cifre binarie
\item Quindi la complessità è $O(nk) = O(n \cdot 2^t)$, esponenziale
\EIL

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Problemi fortemente, debolmente \NP-completi}

\vspace{-9pt}
\begin{myboxtitle}[Dimensioni del problema]
Dato un problema decisionale $R$ e una sua istanza $I$:
\BIL
\item La \alert{dimensione $d$} di $I$ è la lunghezza della stringa che codifica $I$
\item Il \alert{valore \#} è il più grande numero intero che appare in $I$
\EIL
\end{myboxtitle}

\begin{myboxtitle}[Esempi]
\small
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Nome} & $I$ & \# & $d$ \\\hline
\textsc{subset-sum} & $ \{n, k, A\}$ & $\max\{n, k, \max(A)\}$ & $O(n \log \#)$ \\\hline
\textsc{clique} & \phantom{$\{n, m, k, G \}$} & \phantom{$\max\{n, m, k\}$} & \phantom{$O(n + m + \log\#)$}\\\hline
\textsc{tsp} & \phantom{$\{n, k, d \}$} & \phantom{$\max\{n, k, \max(d)\}$} &
\phantom{$O(n^2 \log \#)$} \\\hline
\end{tabular}
\end{myboxtitle}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Esempio: Cricca}

\vspace{-9pt}
\begin{myboxtitle}[Cricca (\textsc{clique})]
Dati un grafo non orientato ed un intero $k$, esiste un sottoinsieme di almeno
$k$ nodi tutti mutuamente adiacenti?
\end{myboxtitle}

\IG{0.40}{clique.png}

\vfill
\tiny
\url{https://en.wikipedia.org/wiki/Clique_(graph_theory)}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Esempio: Commesso viaggiatore}

\vspace{-9pt}
\begin{myboxtitle}[Commesso viaggiatore (Traveling salesperson - \textsc{tsp})]
Date $n$ città e una matrice simmetrica $d$ di distanze positive, dove $d[i][j]$ è la distanza fra $i$ e $j$, trovare un percorso
che, partendo da una qualsiasi città, attraversi ogni città esattamente una
volta e ritorni alla città di partenza, in modo che la distanza totale
percorsa sia minima.
\end{myboxtitle}

\begin{center}
\IG{0.45}{tsp.png}
\end{center}

\vfill
\tiny
\url{https://optimization.mccormick.northwestern.edu/images/e/ea/48StatesTSP.png}


\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Problemi fortemente, debolmente \NP-completi}

\vspace{-9pt}
\begin{myboxtitle}[Dimensioni del problema]
Dato un problema decisionale $R$ e una sua istanza $I$:
\BIL
\item La \alert{dimensione $d$} di $I$ è la lunghezza della stringa che codifica $I$
\item Il \alert{valore \#} è il più grande numero intero che appare in $I$
\EIL
\end{myboxtitle}

\begin{myboxtitle}[Esempi]
\small
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Nome} & $I$ & \# & $d$ \\\hline
\textsc{subset-sum} & $ \{n, k, A\}$ & $\max\{n, k, \max(A)\}$ & $O(n \log \#)$ \\\hline
\textsc{clique} & $\{n, m, k, G \}$ & $\max\{n, m, k\}$ & $O(n + m + \log\#)$\\\hline
\textsc{tsp} & $\{n, k, d \}$ & $\max\{n, k, \max(d)\}$ &
$O(n^2 \log \#)$ \\\hline
\end{tabular}
\end{myboxtitle}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Problemi fortemente, debolmente \NP-completi}

\vspace{-9pt}
\begin{myboxtitle}[Definizione]
Sia $R_{\mathit{pol}}$ il problema $R$ ristretto a quei dati d'ingresso per i quali \# è
limitato superiormente da $p(d)$, con $p$ funzione polinomiale in $d$. \\
$R$ è \alert{fortemente \NP-completo} se $R_{\mathit{pol}}$ è \NP-completo
\end{myboxtitle}

\begin{myboxtitle}[Definizione]
Se un problema \NP-completo non è fortemente \NP-completo, \\
allora è \alert{debolmente \NP-completo}.    
\end{myboxtitle}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Esempio: Problema debolmente \NP-completo}

\vspace{-9pt}
\begin{myboxtitle}[Somma di sottoinsieme (\textsc{subset-sum}]
Dati un vettore $A$ contenente $n$ interi positivi ed un intero positivo $k$, \alert{esiste} un sottoinsieme $S \subseteq \{ 1 \ldots n\}$ tale che 
$\displaystyle \sum_{i \in S} a[i] = k$?
\end{myboxtitle}

\begin{myboxtitle}[Esempio: \textsc{subset-sum} è debolmente \NP-completo]
\BIL
\item $\forall A[i] \leq k$ (valori più grandi di $k$ vanno esclusi)
\item Se $k=O(n^c)$, allora $\# = \max \{n, k, a_1, \ldots, a_n\} = O(n^c)$
\item La soluzione basata su programmazione dinamica ha complessità
$O(nk) = O(n^{c+1})$, quindi in $\PTIME$.
\item Quindi \textsc{subset-sum} non è fortemente \NP-completo
\EIL
\end{myboxtitle}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Algoritmi pseudo-polinomiali}

\vspace{-9pt}
\begin{myboxtitle}[Definizione]
Un algoritmo che risolve un certo problema $R$, per qualsiasi
dato $I$ d'ingresso, in tempo $p(\#, d)$, con $p$ funzione polinomiale in $\#$
e $d$, ha complessità \alert{pseudo-polinomiale}.
\end{myboxtitle}

\begin{myboxtitle}[Esempio]
Gli algoritmi per \textsc{subset-sum} basati su programmazione dinamica e memoization sono pseudo-polinomiali.
\end{myboxtitle}

\begin{myboxtitle}[Teorema]
Nessun problema fortemente \NP-completo può essere risolto da un algoritmo
pseudo-polinomiale, a meno che non sia $\PP = \NP$.
\end{myboxtitle}

\end{frame}



%-------------------------------------------------------------------------
\begin{frame}{Esempio: Problema fortemente \NP-completo}

\vspace{-9pt}
\begin{myboxtitle}[Cricca (\textsc{clique})]
Dati un grafo non orientato ed un intero $k$, esiste un sottoinsieme di almeno
$k$ nodi tutti mutuamente adiacenti?
\end{myboxtitle}

\begin{myboxtitle}[\textsc{clique} è fortemente \NP-completo]
\BIL
\item $k \leq n$ (altrimenti la risposta è \FALSE)
\item $\# = \max \{ n, m, k \} = \max \{ n, m \}$
\item $d = O(n + m + \log \#) = O(n+m)$
\item Quindi $\# = \max \{ n, m \}$ è limitato superiormente da $O(n+m)$
\item Il problema ristretto è identico a \textsc{clique}, che è \NP-completo
\EIL
\end{myboxtitle}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Esempio:  Problema fortemente \NP-completo}

\vspace{-9pt}
\begin{myboxtitle}[Commesso viaggiatore (Traveling salesperson - \textsc{tsp})]
Date $n$ città e una matrice simmetrica $d$ di distanze positive, dove $d[i][j]$ è la distanza fra $i$ e $j$, trovare un percorso
che, partendo da una qualsiasi città, attraversi ogni città esattamente una
volta e ritorni alla città di partenza, in modo che la distanza totale
percorsa sia minima.
\end{myboxtitle}

\begin{myboxtitle}[\textsc{tsp} è fortemente \NP-completo]
\BIL
\item Per assurdo, supponiamo \textsc{tsp} sia debolmente \NP-completo
\item Allora esiste una soluzione pseudo-polinomiale
\item Usiamo questa soluzione per risolvere un problema \NP-completo in
  tempo polinomiale - assurdo a meno che $\PP=\NP$
\EIL
\end{myboxtitle}
\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Circuito hamiltoniano}

\vspace{-9pt}
\begin{myboxtitle}[Circuito hamiltoniano (\textsc{hamiltonian-circuit})]
Dato un grafo non orientato $G$, esiste un circuito che attraversi ogni nodo
una e una sola volta?
\end{myboxtitle}

\vspace{-9pt}
\TwoColsCustom{0.4}{0.55}{
\begin{center}
\IG{1.0}{hamiltonian-path.pdf}
\end{center}
}{
\begin{myboxtitle}[Complessità]
\BIL
\item \textsc{hamiltonian-circuit} è \NP-completo
\item \EE uno dei 21 problemi elencati nell'articolo di Karp
\EIL
\end{myboxtitle}
}

\vfill
\tiny
\url{https://en.wikipedia.org/wiki/Hamiltonian\_path\#/media/File:Hamiltonian\_path.svg}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Esempio: Problema fortemente \NP-completo}

\vspace{-9pt}
\BB{Dimostriamo che $\textsc{tsp}$ è fortemente \NP-completo}
\BIL
\item Sia $G=(V,E)$ un grafo non orientato 
\item Definiamo una matrice di distanze a partire da $G$
\medskip
\[
  d[i][j] = \begin{cases}
    1 & (i,j) \in E \\
    2 & (i,j) \notin E
  \end{cases}
\]    

\item Il grafo $G$ ha un circuito hamiltoniano se e solo se è possibile
trovare un percorso da commesso viaggiatore di costo $n$
\item Se esistesse un algoritmo pseudopolinomiale $A$ per $\textsc{tsp}$, \\
\textsc{hamiltonian circuit} potrebbe essere risolto da $A$ in tempo polinomiale
\EIL
\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Problemi debolmente/fortemente \NP-completi?}

\vspace{-18pt}
\TwoCols{
\begin{myboxtitle}[Partizione (\textsc{partition})]
Dato un vettore $A$ contenente $n$ interi positivi, esiste un
sottoinsieme $S \subseteq \{1 \ldots n\}$ tale che $\displaystyle \sum_{i\in S} A[i] = \sum_{i \notin S} A[i]$ ?
\end{myboxtitle}
}{
\begin{myboxtitle}[Esempio]
\begin{overprint}
\onslide<1|handout:0>
\begin{tabular}{|c|c|c|c|c|c|}
\hline
14 & 6 & 12 & 3 & 7 & 2 \\\hline
\end{tabular}
\onslide<2|handout:1>
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\R{14} & \R{6} & \B{12} & \B{3} & \B{7} & \R{2} \\\hline
\end{tabular}
\end{overprint}
\end{myboxtitle}
}

\begin{myboxtitle}[Domanda -- \textsc{partition} è debolmente \NP-completo?]
\begin{overprint}
\onslide<1|handout:0>
~
\onslide<2|handout:1>
Sì, perchè è possibile ridurlo a \textsc{subset-sum} scegliendo come
valore $k$ la metà di tutti i valori presenti:

\[
  k = \frac{\sum_{i=1}^n A[i]}{2} = \frac{44}{2} = 22
\]
\end{overprint}
\end{myboxtitle}

\end{frame}



%-------------------------------------------------------------------------
\begin{frame}{Problemi debolmente/fortemente \NP-completi}

\vspace{-9pt}
\begin{myboxtitle}[3-Partizione (\textsc{3-partition})]
Dati $3n$ interi $\{a_1, \mldots, a_{3n}\}$, esiste una partizione in $n$
triple $T_1, \mldots, T_n$, tale che la somma dei tre elementi di ogni $T_j$ è
la stessa, per $1 \le j \le n$?
\end{myboxtitle}

\begin{myboxtitle}[Domanda -- \textsc{3-partition} è debolmente \NP-completo?]
\begin{overprint}
\onslide<1|handout:0>
~
\onslide<2|handout:1>
No, non esiste un algoritmo pseudo-polinomiale per risolvere 3-partition.
\end{overprint}
\end{myboxtitle}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algoritmi di approssimazione}

%-------------------------------------------------------------------------
\begin{frame}{Algoritmi di approssimizzazione}

\vspace{-9pt}
\begin{myboxtitle}[Premessa]
\BIL
\item I problemi più interessanti sono in forma di ottimizzazione
\item Se il problema di decisione è \NP-completo, non sono noti 
algoritmi polinomiali per il problema di ottimizzazione
\item Esistono algoritmi polinomiali che trovano soluzioni ammissibili
più o meno vicine a quella ottima
\EIL
\end{myboxtitle}

\begin{myboxtitle}[Algoritmi di approssimazione]
Se è possibile dimostrare un limite superiore/inferiore al rapporto fra la soluzione trovata e la soluzione ottima, allora tali algoritmi
vengono detti \alert{algoritmi di approssimazione}.
\end{myboxtitle}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Approssimazione}

\vspace{-9pt}
\begin{myboxtitle}[Definizione]
Dato un problema di ottimizzazione con funzione costo non negativa $c$,
un algoritmo si dice di \alert{$\alpha(n)$-approssimazione} se fornisce una soluzione ammissibile $x$ il cui costo $c(x)$ non si discosta dal costo $c(x^*)$ della soluzione ottima $x^*$ per più di un fattore $\alpha(n)$,
per qualunque input di dimensione $n$:

\begin{align*}
c(x^*) \leq c(x) & \leq \alpha(n) c(x^*)  && \alpha(n) > 1 \qquad (\textrm{Minimizzazione})\\
\alpha(n) c(x^*) \leq c(x) & \leq c(x^*)  && \alpha(n) < 1 \qquad (\textrm{Massimizzazione})
\end{align*}
\end{myboxtitle}

\BIL
\item $\alpha(n)$ può essere una costante, valida per tutti gli $n$
\item Identificare un valore $\alpha(n)$ e dimostrare che l'algoritmo lo rispetta è ciò che rende un buon algoritmo un algoritmo di approssimazione
\EIL


\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Esempio}

\vspace{-9pt}
\begin{myboxtitle}[Bin packing]
Dati:
\BI
\item un vettore $A$ contenente $n$ interi positivi (i \alert{volumi}
degli \alert{oggetti}) 
\item un intero positivo $k$ (la \alert{capacità} di una \alert{scatola}, tale che $\forall i: A[i] \leq k$), 
\EI
si vuole trovare una partizione di $\{1, \mldots, n\}$ nel minimo numero di sottoinsiemi disgiunti (``scatole'') tali che $\sum_{i\in S} A[i] \le k$ per ogni insieme $S$ della partizione
\end{myboxtitle}

\vspace{-9pt}
\TwoColsCustom{0.45}{0.53}{
\begin{myboxtitle}[Esempio]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
3 & 7 & 2 & 5 & 4 & 3 & 5 \\\hline
\end{tabular}
\end{myboxtitle}
}{
\begin{myboxtitle}[Domanda]
Come risolvereste il problema?
\end{myboxtitle}
}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{First-fit}

\vspace{-9pt}
\begin{myboxtitle}[Algoritmo \textsc{first-fit}]
Gli oggetti sono considerati in un ordine qualsiasi e ciascun oggetto è assegnato alla prima scatola che lo può contenere, tenuto conto di quanto
spazio è stato occupato della stessa. (Algoritmo Greedy)
\end{myboxtitle}

\bigskip
\begin{myboxtitle}[Esempio]

\bigskip
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
3 & 7 & 2 & 5 & 4 & 3 & 5 \\\hline
\end{tabular}

\bigskip
$k=8$

\bigskip
\begin{overprint}
    
\onslide<1|handout:0>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
&&&& \\\hline
\end{tabular}

\onslide<2|handout:0>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
3 &&&& \\\hline
\end{tabular}

\onslide<3|handout:0>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
3 & 7 &&& \\\hline
\end{tabular}

\onslide<4|handout:0>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
3, 2 & 7 &&& \\\hline
\end{tabular}

\onslide<5|handout:0>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
3, 2 & 7 & 5 && \\\hline
\end{tabular}

\onslide<6|handout:0>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
3, 2 & 7 & 5 & 4 & \\\hline
\end{tabular}

\onslide<7|handout:0>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
3, 2, 3 & 7 & 5 & 4 &\\\hline
\end{tabular}

\onslide<8|handout:1>
\begin{tabular}{|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|P{1.1cm}|}
\hline
3, 2, 3 & 7 & 5 & 4 & 5 \\\hline
\end{tabular}

\end{overprint}
\end{myboxtitle}

\end{frame}

\begin{frame}{Approssimazione First-Fit}

\vspace{-12pt}
\BIL
\item Sia $N>1$ il numero di scatole usate da \textsc{first-fit}\\ 
(se $N=1$, \textsc{first-fit} è ottimale)

\item Il numero minimo di scatole $N^*$ è limitato da:
\medskip
\[
  N^* \geq \frac{\sum_{i = 1}^{n} A[i]}{k} = \frac{29}{8}  =  3.625
\]
\item Non possono esserci due scatole riempite meno della metà:
\medskip
\[
  N < \frac{\sum_{i = 1}^{n} A[i]}{k/2} = \frac{29}{8/2} = 7.250 
\]

\item Abbiamo quindi:
\[
 N < \frac{\sum_{i = 1}^{n} A[i]}{k/2} = 2 \frac{\sum_{i = 1}^{n} A[i]}{k} \leq 2 N^* = \alpha(n) N^*
\]
che implica $\alpha(n) = 2$
\EIL

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Approssimazione First-Fit}

\vspace{-9pt}
\BIL
\item \EE possibile dimostrare un risultato migliore per \FF:
\medskip
\[
  N < \frac{17}{10}N^* + 2
\]  
\item Variante FFD (First-fit decreasing): gli oggetti sono considerati
in ordine non decrescente
\[
  N < \frac{11}{9}N^* + 4
\]
\item Queste sono dimostrazioni di limiti superiori per il fattore
$\alpha(n)$, per casi particolari l'approssimazione può essere migliore
\EIL

\end{frame}







%-------------------------------------------------------------------------
\begin{frame}{Commesso viaggiatore con disuguaglianze particolari}

\vspace{-9pt}
\begin{myboxtitle}[Commesso viaggiatore con dis. triangolari ($\Delta$-\textsc{tsp})]
Siano date $n$ città e le distanze (positive) $d[i][j]$ tra esse, \alert{tali per cui vale
la regola delle diseguaglianze triangolari:
\smallskip
\[
d[i][j] \le d[i][k] + d[k][j] \quad \forall i,j,k : \quad 1 \le i, j, k \le n
\]}
Trovare un percorso
che, partendo da una qualsiasi città, attraversi ogni città esattamente una
volta e ritorni alla città di partenza, in modo che la distanza complessiva
percorsa sia minima.
\end{myboxtitle}

\TwoCols{
Con diseguaglianza triangolare
\begin{center}
\includegraphics[width=0.6\textwidth,page=1]{distriangolare.pdf}
\end{center}
}{
Senza diseguaglianza triangolare
\begin{center}
\includegraphics[width=0.6\textwidth,page=2]{distriangolare.pdf}
\end{center}
}


\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{$\Delta$-\textsc{tsp} è \NP-completo}

\vspace{-9pt}
\BB{Dimostriamo che $\textsc{hamiltonian-circuit} \leq_p \textrm{$\Delta$-\textsc{tsp}}$}
\BIL
\item Sia $G=(V,E)$ un grafo non orientato 
\item Definiamo una matrice di distanze a partire da $G$
\medskip
\[
  d[i][j] = \begin{cases}
    1 & (i,j) \in E \\
    2 & (i,j) \notin E
  \end{cases}
\]    

\item Il grafo $G$ ha un circuito hamiltoniano se e solo se è possibile
trovare un percorso da commesso viaggiatore lungo $n$
\item Valgono le diseguaglianze triangolari: 
\medskip
\[
  d[i][j] \leq 2 \leq d[i][k]+d[k][j]
\]
\EIL
\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Commesso viaggiatore vs circuito hamiltoniano pesato}


\vspace{-9pt}
\BIL
\item Interpretiamo ($\Delta$)-\textsc{tsp} come il problema di trovare
un circuito hamiltoniano di peso minimo su un grafo completo
\EIL

\TwoCols{
\vspace{-9pt}
\IG{0.8}{tsp-greedy.pdf}
}{
\medskip
\includegraphics<1|handout:1>[width=0.8\textwidth,page=1]{tsp-pentagon.pdf}
\includegraphics<2|handout:2>[width=0.8\textwidth,page=9]{tsp-pentagon.pdf}
\includegraphics<3|handout:3>[width=0.8\textwidth,page=5]{tsp-local.pdf}

\bigskip
\begin{overprint}
\onslide<2|handout:2>\alert{Costo: $21$}
\onslide<3|handout:3>\alert{Costo: $19$}
\end{overprint}
}
\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Algoritmo di approssimazione per $\Delta$-\textsc{tsp}}

\vspace{-9pt}
\BIL
\item Interpretiamo $\Delta$-\textsc{tsp} come il problema di trovare
un circuito hamiltoniano di peso minimo su un grafo completo
\item Si consideri un circuito hamiltoniano e si cancelli un suo arco
\item Si ottiene un albero di copertura
\EIL

\medskip
\IG{0.55}{toscana-hamilton.pdf}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Algoritmo di approssimazione per $\Delta$-\textsc{tsp}}

\vspace{-9pt}
\begin{myboxtitle}[Teorema]
Qualunque circuito hamiltoniano $\pi$ ha costo $c(\pi)$ superiore al costo $\mathit{mst}$ di un albero di copertura di peso minimo, ovvero $\mathit{mst} < c(\pi)$
\end{myboxtitle}    

\begin{myboxtitle}[Dimostrazione]
Per assurdo
\BIL 
\item Supponiamo che esista un circuito hamiltoniano $\pi$ di costo $c(\pi) \leq \mathit{mst}$
\item Togliamo un arco, otteniamo un albero di copertura con peso inferiore
$\mathit{mst}' < c(\pi) \leq \mathit{mst}$
\item Contraddizione, visto che $\mathit{mst}$ è il costo minimo fra tutti gli alberi di copertura 
\EIL
\end{myboxtitle}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Algoritmo per $\Delta$-\textsc{tsp}}

\vspace{-9pt}
\BIL
\item Si individua un minimo albero di copertura di peso $\mathit{mst}$ e se ne percorrono gli archi due volte, prima in un senso e poi nell'altro 
\item In questo modo, si visita ogni città almeno una volta
\item La distanza complessiva di tale circuito è uguale a $2 \cdot \mathit{mst}$
\item Ma non è un circuito hamiltoniano!
\EIL

\vspace{-12pt}
\TwoCols{
\IG{1.0}{toscana-mst.pdf}
}{
\IG{1.0}{toscana-mst2.pdf}
}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Algoritmo per $\Delta$-\textsc{tsp}}

\vspace{-9pt}
\BIL
\item Si evita di passare per città già visitate - si saltano
\item Per la disuguaglianza triangolare, il costo $c(\pi)$ del circuito così
ottenuto è inferiore o uguale a $2 \cdot \mathit{mst}$
\item Quindi:
$
  c(\pi) \leq 2 \cdot \mathit{mst} < 2 \cdot c(\pi^*) \quad \Rightarrow \quad \alpha(n) = 2
$\\
dove $c(\pi^*)$ è il costo del circuito hamiltoniano ottimo
\EIL

\vspace{-12pt}
\TwoCols{
\IG{1.0}{toscana-algo.pdf}
}{
\IG{1.0}{toscana-percorso.pdf}
}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Algoritmo per $\Delta$-\textsc{tsp}}

\vspace{-9pt}
\begin{myboxtitle}[Note]
\BIL
\item La complessità dell'algoritmo è pari a $O(n^2 \log n)$:
  \BI
  \item $O(n^2 \log n)$ per algoritmo di Kruskal
  \item $O(n)$ per visita in profondità del MST raddoppiato con $2n$ archi
  \EI
\item Esistono grafi "perversi" per cui il fattore di approssimazione tende
al valore $2$
\item L'algoritmo di Christofides (1976) ha un fattore di approssimazione
di $3/2$, il migliore risultato al momento
\EIL
\end{myboxtitle}
  
\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Non approssimabilità di \textsc{tsp}}

\vspace{-9pt}
\begin{myboxtitle}[Teorema]
Non esiste alcun algoritmo di $\alpha(n)$-approssimazione per 
\textsc{tsp} tale che $c(x') \le sc(x^*)$, con $s \geq 2$ intero positivo, a meno che non sia $\PP = \NP$.
\end{myboxtitle}

\begin{myboxtitle}[Dimostrazione]
Per chi è interessato, nel libro.
\end{myboxtitle}
% \BIL
% \item Per assurdo, supponiamo che un tale algoritmo $A$ esista
% \item Si consideri la riduzione $\textsc{hamiltonian-circuit} \leq_p \textsc{tsp}$
% \item Ovvero, sia dato un grafo $G=(V,E)$ e sia $d$ una
% matrice di distanze tale che:
% \[
% d[i][j] = \begin{cases}
% 1, &\textrm{se $[i, j] \in E$},\\
% sn, &\textrm{se $[i, j] \notin E$}.
% \end{cases}
% \]
% \EIL
% \end{myboxtitle}
\end{frame}

% %-------------------------------------------------------------------------
% \begin{frame}{Non approssimabilità di \textsc{tsp}}
%
% \vspace{-9pt}
% \begin{myboxtitle}[Teorema]
% Non esiste alcun algoritmo di approssimazione assoluta per il
% \textsc{tsp} tale che
% \probref{Commesso viaggiatore} tale che $c(x') \le sc(x^*)$, con $s \geq 2$ intero positivo, a meno che non sia $\PP = \NP$.
% \end{myboxtitle}
%
% \begin{myboxtitle}[Dimostrazione]
% \BIL
%   \item Caso 1: Se $G$ ha un circuito Hamiltoniano, allora $c(x^*) = n$, quindi $A$ fornisce, in tempo polinomiale, una soluzione $x'$ tale che $c(x') \le sc(x^*) = sn$
%   \item Caso 2: Se $G$ non ha un circuito Hamiltoniano, allora $c(x^*) > sn$, quindi
%   $A$ fornisce, in tempo polinomiale, una soluzione $x'$ tale che $c(x') \geq c(x^*) > sn$
% \item Quindi $A$ risolve $\textsc{hamiltonian-circuit}$ in tempo polinomiale,
% impossibile a meno che $\PP = \NP$
% \EIL
% \end{myboxtitle}
%
% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algoritmi euristici}

%-------------------------------------------------------------------------
\begin{frame}{Algoritmi euristici}

\vspace{-9pt}
\begin{myboxtitle}[Euristiche]
Quando si è presi dalla disperazione a causa della enorme difficoltà di un
problema di ottimizzazione NP-hard, si può ricorrere ad algoritmi
``euristici'' che forniscono una soluzione ammissibile
\BIL
\item non necessariamente ottima 
\item non necessariamente approssimata 
\EI

Dal greco antico $\mathit{\epsilon\upsilon\rho\iota\sigma\kappa\omega}$ %εὑρίσκω 
(eurisko), "Trovare, scoprire”
\end{myboxtitle}

\begin{myboxtitle}[Tecniche possibili]
\BI
\item Greedy
\item Ricerca locale
\EI
\end{myboxtitle}
    
\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{\textsc{tsp} -- Greedy (1)}

\vspace{-9pt}
\begin{myboxtitle}[Shortest edges first]
\BIL
\item Ordiniamo gli archi per pesi non decrescenti
\item Aggiungiamo archi alla soluzioni seguendo questo ordine finché non 
  sono stati aggiunti $n-1$ archi, dove $n$ è il numero di nodi.
\item Per poter aggiungere un arco, occorre verificare che:
  \BI
  \item per ciascuno dei suoi nodi non siano stati già scelti due archi
  \item che non si formino circuiti (\mfset)
  \EI
\item A questo punto, si è trovata una catena Hamiltoniana
\item Si chiude il circuito aggiungendo l'arco tra i due nodi estremi della catena
\EIL
\end{myboxtitle}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Esempio}

\vspace{-9pt}
\TwoCols{
\vspace{-18pt}
\IG{1.0}{tsp-greedy.pdf}
}{
\includegraphics<1|handout:1>[width=\textwidth,page=1]{tsp-pentagon.pdf}
\includegraphics<2|handout:0>[width=\textwidth,page=2]{tsp-pentagon.pdf}
\includegraphics<3|handout:0>[width=\textwidth,page=3]{tsp-pentagon.pdf}
\includegraphics<4|handout:0>[width=\textwidth,page=4]{tsp-pentagon.pdf}
\includegraphics<5|handout:0>[width=\textwidth,page=5]{tsp-pentagon.pdf}
\includegraphics<6|handout:0>[width=\textwidth,page=6]{tsp-pentagon.pdf}
\includegraphics<7|handout:0>[width=\textwidth,page=7]{tsp-pentagon.pdf}
\includegraphics<8|handout:2>[width=\textwidth,page=8]{tsp-pentagon.pdf}
}

\alert{
\bigskip
\onslide<8|handout:2>Costo: $21$
}


\end{frame}

%-------------------------------------------------------------------------
\begin{frame}[shrink=10]{\textsc{tsp} -- Greedy (1)}

\vspace{-12pt}
\begin{Procedure}
\caption[A]{\Set\ \greedyTsp(\Graph $G$)}
$\Set\ \mathit{result} = \setconstructor()$\;
$\mfset\ M = \mfconstructor(G.n)$\;
$\INTEGER[\,]\ \mathit{edges} = \NEW\ \INTEGER[1 \ldots n]$ = \{ 0 \}\REMR{N. archi nella catena}
$A = \{ \textrm{ordina gli archi per peso non decrescente} \}$\;
\ForEach{$(u,v) \in A$}{
  \If{$\mathit{edges}[u] < 2$ \AND $\mathit{edges}[v]<2$ \AND $M.\mffind(u) \neq M.\mffind(v)$}{
    $\mathit{result}.\setinsert(~(u,v)~)$\;
    $\mathit{edges}[u] = \mathit{edges}[u]+1$\;
    $\mathit{edges}[v] = \mathit{edges}[v]+1$\;
    $M.\mfmerge(u,v)$\;
  }
}
\INTEGER $u = 1$;
\lWhile{$\mathit{edges}[u] \neq 1$}{$u = u+1$}
\INTEGER $v = u+1$; 
\lWhile{$\mathit{edges}[v] \neq 1$}{$v = v+1$}
$\mathit{result}.\setinsert(~(u,v)~)$\;
\Return $\mathit{result}$\;
\end{Procedure}

\end{frame}



%-------------------------------------------------------------------------
\begin{frame}{\textsc{tsp} -- Greedy (2)}

\vspace{-9pt}
\begin{myboxtitle}[Nearest neighbor]
\BIL
\item Si parte da una città
\item Si seleziona come prossima città quella più vicina
\item Si va avanti così, evitando città già visitate
\item Quando si sono visitate tutte le città, si torna alla città di
partenza
\item Si può lavorare direttamente sulla matrice
\EIL
\end{myboxtitle}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{\textsc{tsp} -- Greedy (2)}

\vspace{-9pt}
\TwoCols{
\vspace{-18pt}
\IG{1.0}{tsp-greedy.pdf}
}{
\includegraphics<1|handout:1>[width=\textwidth,page=1]{tsp-nn.pdf}
\includegraphics<2|handout:0>[width=\textwidth,page=2]{tsp-nn.pdf}
\includegraphics<3|handout:0>[width=\textwidth,page=3]{tsp-nn.pdf}
\includegraphics<4|handout:0>[width=\textwidth,page=4]{tsp-nn.pdf}
\includegraphics<5|handout:0>[width=\textwidth,page=5]{tsp-nn.pdf}
\includegraphics<6|handout:2>[width=\textwidth,page=6]{tsp-nn.pdf}
}

\alert{
\bigskip
\onslide<6|handout:2>Costo: $21$
}


\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{\textsc{tsp} -- Greedy}

\vspace{-9pt}
\BIL
\item Costo computazionale:
  \BI
  \item Greedy 1: $O(n^2 \log n)$ (ordinamento archi)
  \item Greedy 2: $O(n^2)$
  \EI
\item La soluzione così ottenuta si può utilizzare come:
\BI
\item base di partenza per un algoritmo branch-\&-bound
\item può essere migliorata ancora tramite ricerca locale
\EI
\EIL

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{\textsc{tsp} -- Approccio ricerca locale}

\vspace{-9pt}
\begin{myboxtitle}[Ricerca locale]
Sia $\pi$ un circuito Hamiltoniano del grafo completo derivante dal problema
\textsc{tsp}. Si consideri il seguente intorno:
\[
I_2(\pi) = \parbox[t]{9cm}{\{$\pi'$: $\pi'$ è ottenuto da
$\pi$ cancellando due archi non consecutivi del circuito e
sostituendoli con due archi esterni al circuito\}}
\]
\end{myboxtitle}

\begin{myboxtitle}[Note]
\BIL
\item $|I_2(\pi)| = n(n - 1)/2 - n$
  \BI
  \item Ci sono $n(n-1)/2$ coppie di archi del circuito
  \item $n$ di esse sono consecutive
  \item Una volta spezzato un circuito, esiste un solo modo per riconnetterlo
  \EI
\item Costo per esaminare $I_2(\pi)$: $O(n^2)$
\EIL
\end{myboxtitle}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Esempio}

\vspace{-9pt}
\TwoCols{
\vspace{-18pt}
\IG{1.0}{tsp-greedy.pdf}
}{
\includegraphics<1|handout:1>[width=\textwidth,page=1]{tsp-local.pdf}
\includegraphics<2|handout:0>[width=\textwidth,page=2]{tsp-local.pdf}
\includegraphics<3|handout:2>[width=\textwidth,page=3]{tsp-local.pdf}
\includegraphics<4|handout:0>[width=\textwidth,page=4]{tsp-local.pdf}
\includegraphics<5|handout:3>[width=\textwidth,page=5]{tsp-local.pdf}
}

\alert{
\bigskip
\begin{overprint}
\onslide<1-2|handout:1>Costo: $25$
\onslide<3-4|handout:2>Costo: $23$
\onslide<5|handout:3>Costo: $19$
\end{overprint}
}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Algoritmi euristici}
    
\vspace{-9pt}
\BB{
A heuristic is an algorithm that doesn’t work. \\
(Except in practice. Sometimes. Maybe)
~\\
\begin{flushright}Jeff Erickson\end{flushright}

}
    
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algoritmi branch-\&-bound}

\begin{frame}{Branch-\&-bound}

\vspace{-9pt}
\begin{myboxtitle}[Branch-\&-bound]
Per risolvere un problema di ottimizzazione NP-arduo, si può modificare la
procedura \enumerazione(), vista nella sezione su Backtrack, in modo da
"potare" certe sequenze di scelte che si rivelino incapaci di
generare la soluzione ottima
\end{myboxtitle}

\begin{myboxtitle}[Assunzioni -- senza perdere (troppa) generalità]
\BIL
\item Problema di minimizzazione
\item Ogni sequenza di scelte abbia costo non negativo
\item Ogni scelta, aggiunta alle scelte già effettuate, non faccia 
diminuire il costo della soluzione parziale così costruita
\EIL
\end{myboxtitle}
    
\end{frame}

\begin{frame}{Backtrack: ripasso}

\vspace{-9pt}    
\begin{Procedure}
\caption[A]{\textcolor{violet}{\enumerazione}($\langle \mathit{dati\ problema} \rangle$, $\Item[\,]\ S$, \INTEGER\ $i$, $\langle \mathit{dati\ parziali} \rangle)$}
\uIf{$\textcolor{violet}{\isAdmissible}(\langle \mathit{dati\ problema} \rangle, S, i, \langle \mathit{dati\ parziali} \rangle)$}
{
  $\textcolor{violet}{\processSolution}(\langle \mathit{dati\ problema} \rangle, S, i, \langle \mathit{dati\ parziali} \rangle)$\;
  
  \alert{\Return \TRUE}\REMR{Trovata soluzione, restituisco \TRUE}
}
\uElseIf{$\textcolor{violet}{\isImpossible}(\langle \mathit{dati\ problema} \rangle, S, i, \langle \mathit{dati\ parziali} \rangle)$}{
  \alert{\Return \FALSE}\REMR{Impossibile trovare soluzioni, restituisco \FALSE}
}
\Else{
  $\Set\ C = \textcolor{violet}{\getChoices}(\langle \mathit{dati\ problema} \rangle, S, i, \langle \mathit{dati\ parziali} \rangle)$\;
  \ForEach{$c \in C$}
  {
    $S[i] = c$\;
    \If{$\textcolor{violet}{\enumerazione}(\langle \mathit{dati\ problema} \rangle, S, i+1, \langle \mathit{dati\ parziali} \rangle)$}{
      \alert{\Return \TRUE}\REMR{Trovata soluzione, restituisco \TRUE}
    }
  }
  \alert{\Return \FALSE}\REMR{Nessuna soluzione, restituisco \FALSE}
}
\end{Procedure}
        
\end{frame}

\begin{frame}{Branch-\&-bound}

\vspace{-9pt}
\begin{myboxtitle}[Upper bound]
\BIL
\item Durante l'enumerazione, si mantengono informazioni 
\BI
\item sulla miglior soluzione ammissibile \alert{\Minsol} 
\item il suo costo \alert{\Mincost}
\EI
\item \Mincost costituisce un \alert{limite superiore} (\alert{upper bound})
per il costo della soluzione minima
\EIL
\end{myboxtitle}

\begin{myboxtitle}[Lower bound]
\BIL
\item Si supponga di avere disposizione una opportuna funzione \alert{lower bound} $\LB(\langle \mathit{dati\ problema} \rangle, S, i, \langle \mathit{dati\ parziali} \rangle)$, che:
  \BI 
  \item dipenda dalla sequenza di scelte fatte $S[1  \ldots i]$
  \item garantisca che tutte le soluzioni ammissibili generabili facendo
nuove scelte abbiano costo $\geq \LB()$
  \EI
\EIL
\end{myboxtitle}
    
\end{frame}

\begin{frame}{Branch-\&-bound}

\vspace{-9pt}
\begin{myboxtitle}[Potatura]
Se $\LB()$ è maggiore o uguale a \Mincost, allora si può
evitare di generare ed esplorare il sottoalbero delle scelte radicato in tal
nodo
\end{myboxtitle}

\IG{1.0}{albero10.pdf}
\end{frame}

\begin{frame}{Branch-\&-bound}

\vspace{-9pt}
\begin{myboxtitle}[Note]
\BIL
\item Questo metodo non migliora la complessità (superpolinomiale) della procedura \enumerazione()
\item Ne abbassa drasticamente il tempo di esecuzione in pratica
\item Tutto dipende dalla funzione \LB, che deve approssimare il più  possibile il costo della soluzione ottima
\EIL
\end{myboxtitle}

\end{frame}

\begin{frame}{Schema generale}

\vspace{-12pt}
\begin{Procedure}
\caption[A]{\branchbound($\langle \mathit{dati\ problema} \rangle$, $\Item[\,]\ S$, \INTEGER\ $i$, $\langle \mathit{dati\ parziali} \rangle$)}
$\Set\ C = \getChoices(\langle \mathit{dati\ problema} \rangle, S, i, \langle \mathit{dati\ parziali} \rangle)$\;
\ForEach{$c \in C$}{
  $S[i] = c$\;
  $\INTEGER\ \mathit{lb} = \LB(\langle \mathit{dati\ problema} \rangle, S, i, \langle \mathit{dati\ parziali} \rangle)$\;
  \If{$\mathit{lb} < \Mincost$}{
    \eIf{$i < n$}{
      $\branchbound(\langle \mathit{dati\ problema} \rangle, S, i+1, \langle \mathit{dati\ parziali} \rangle)$\;
    }{
      \If{$\fontproc{cost}(S, i) < \Mincost$}{
        $\Minsol = S$\REMR{Variabile globale}
        $\Mincost = \fontproc{cost}(S, i)$\REMR{Variabile globale}
      }
    }
  }
}
\end{Procedure}

\end{frame}

\begin{frame}{Commesso viaggiatore -- Branch-\&-bound}

\vspace{-9pt}
\BIL
\item Sia $n$ il numero di città
\item $d[h][k]$ la distanza intera positiva fra le città $h$ e $k$
\item Al passo $i$-esimo sono state fatte le scelte $S[1 \ldots i]$ 
prese dall'insieme $\{1, \mldots, n\}$
\item Un percorso ammissibile che "espande" $S[1 \ldots i]$ deve
  \BI
  \item attraversare le città $S[1 \ldots i]$
  \item passare da $S[i]$ ad una qualsiasi delle rimanenti $n - i$ città
  \item attraversare queste ultime città in un ordine qualsiasi
  \item da una di queste si ritorna ad $S[1]$
  \EI
\EIL
\end{frame}



\begin{frame}{Commesso viaggiatore -- Branch-\&-bound}

\BIL
\item Distanza percorsa finora
\medskip
\alert{\[
\Cost[i] = \begin{cases}
  0 & i=1 \\
  \Cost[i-1] + d[S[i-1]][S[i]] & i>1
\end{cases}
\]
}\EIL
\TwoCols{
\BIL
\item Lower bound della distanza per \alert{"uscire"} da $S[i]$ ($O(n)$)
\medskip
\alert{\[
\Out = \min_{h \notin S}\{d[S[i]][h] \}
\]
}\EIL
}{
\BIL
\item Lower bound della distanza per \alert{tornare} a $S[1]$ ($O(n)$)
\medskip
\alert{\[
\Back = \min_{h \notin S} \{ d[h][S[1]] \}
\]}
\EIL
}
\BIL
\item Lower bound della distanza percorsa per attraversare una qualsiasi città $h$ delle $n-i$ città ancora da attraversare, provenendo da (e dirigendosi verso) una città non compresa in $S[2 \ldots i-1]$ ($O(n^3)$)
\medskip
\alert{\[
\forall h \notin S: \Transfer[h] = \min_{p,q \notin S[2 \ldots i-1]}\{d[p][h] + d[h][q] : h \neq p \neq q \}
\]
}\EIL

\end{frame}

\begin{frame}{Lower bound}

\vspace{-9pt}
Se $i<n$, un possibile lower bound $\LB(d, S, i)$ calcola la somma:
\BIL
\item del costo $\Cost[i]$ per arrivare al nodo $S[i]$, già speso
\item metà del costo ottenuto sommando:
\BI
\item il lower bound $\Out$ del costo per andare dal nodo $S[i]$ ad un qualunque altro nodo
\item il lower bound per attraversare i nodi non contenuti in $S$
\item il lower bound $\Back$ del costo per tornare al nodo $S[1]$ da un qualunque altro nodo
\EI
\EIL

\[
\LB(d, S, i) = \Cost[i] + \left\lceil \frac{\Out + \sum_{h \notin S} \Transfer[h] + \Back}{2} \right\rceil 
\]
\end{frame}

\begin{frame}[shrink=12]{Commesso viaggiatore -- Branch-\&-bound}

\vspace{-15pt}
\begin{Procedure}
\caption[A]{\bbTsp($\Item[\,]\ S$, \INTEGER $\Cost$, \Set $R$, \INTEGER $n$, \INTEGER\ $i$)}
$\Set\ \mathit{choices} = \fontproc{copy}(R)$\;
\ForEach{$c \in \mathit{choices}$}{
  $S[i] = c$\;
  $R.\setremove(c)$\;
  \eIf{$i<n$}{
    \{calcola $\Out$, $\Back$, e $\Transfer[h]$ per ogni $h \in R$\}\;
    $\INTEGER\ \mathit{lb} =\Cost[i] + \left\lceil \left(\Out + \sum_{h \notin S} \Transfer[h] + \Back \right) / 2 \right\rceil$\;    
    \If{$\mathit{lb} < \Mincost$}{
      $\bbTsp(S, \Cost + d[S[i - 1]][S[i]], R, n, i+1)$\;
    }
  }{
    $\mathit{cost} = \mathit{cost} + d[S[i]][S[1]]$\;    
    \If{$\mathit{cost} < \Mincost$}{
      $\Minsol = S$\;
      $\Mincost = \mathit{costo}$\;
    }
  }
  $R.\setinsert(c)$\;
}
\end{Procedure}


\end{frame}

\begin{frame}{Dettagli}

\vspace{-9pt}
\TwoColsCustom{0.55}{0.40}{
\BIL
\item $\Mincost$ è una variabile globale
\item Invece di inizializzarla a $+\infty$, possiamo scegliere una 
permutazione a caso
\item Ad esempio, la permutazione 1-2-5-3-4 ha un costo pari a 21
\item Per evitare che lo stesso circuito sia generato più volte, si
parte da un nodo fissato (es. $1$)
\EIL
}{
\includegraphics[width=\textwidth,page=9]{tsp-pentagon.pdf}
}

\end{frame}


%-------------------------------------------------------------------------
\begin{frame}{Esempio}

\vspace{-9pt}
\IG{1.0}{albero-tsp.pdf}

\begin{tikzpicture}[remember picture,overlay]
    \node[xshift=-1.2cm,yshift=-2.3cm] at (current page.north east){%
    \includegraphics[width=1cm]{node-single.pdf}};
\end{tikzpicture}


\begin{tikzpicture}[remember picture,overlay]
    \node[xshift=1.2cm,yshift=-2.3cm] at (current page.north west){%
    \includegraphics[width=2cm]{tsp-pentagon.pdf}};
\end{tikzpicture}

\end{frame}

%-------------------------------------------------------------------------
\begin{frame}{Esempio}

\vspace{-9pt}
\BB{
In questo semplice esempio, è stato possibile "potare" 42 su 65 nodi
}

\begin{myboxtitle}[Possibili miglioramenti]
\BIL
\item \EE possibile variare l'ordine di visita dell'albero delle scelte
  \BI
  \item DFS vs Best-first
  \EI
\item \EE possibile variare il meccanismo di branching
  \BI
  \item Sui nodi, sugli archi, etc.
  \EI
\item \EE possibile cercare dei lower bound più stretti 
  \BI
  \item Held, M., and Karp, R. M. (1971), "The Traveling Salesman Problem and Minimum Spanning Trees: part II", Mathematical Programming 1:6-25
  \EI
\EIL
\end{myboxtitle}

\end{frame}






%-------------------------------------------------------------------------
\begin{frame}{Spunti di lettura}

\vspace{-9pt}
\begin{myboxtitle}[Bibliografia]
\BIL
\item Jeff Erickson. Approximation Algorithms. \\ \url{http://jeffe.cs.illinois.edu/teaching/algorithms/notes/J-approx.pdf}\\
(Per approfondire)
\item David Williamson, David Shmoys (2010). The Design of Approximation Algorithms. Cambridge University Press.\\
\url{http://www.designofapproxalgs.com/book.pdf}\\
(Tanta roba)
\item David L. Applegate, Robert E. Bixby, Vašek Chvátal, and William J. Cook. The Traveling Salesman Problem: A Computational Study. Princeton University Press, 2007.\\
(600 pagine \emph{solo} su \textsc{tsp})
\EIL
\end{myboxtitle}


\end{frame}

%-------------------------------------------------------------------------
\begin{OnlySlides}{Appunti di storia}
    
\includegraphics[width=\textwidth]{dantzig-1.pdf}

\end{OnlySlides}

%-------------------------------------------------------------------------
\begin{OnlySlides}{Appunti di storia}
    
\includegraphics[width=\textwidth]{dantzig-2.pdf}

\end{OnlySlides}

%-------------------------------------------------------------------------
\begin{OnlySlides}{Appunti di storia}
    
\includegraphics[width=\textwidth]{dantzig-3.pdf}

\end{OnlySlides}

%-------------------------------------------------------------------------
\begin{OnlySlides}{Appunti di storia}
    
\includegraphics[width=\textwidth]{dantzig-4.pdf}

\end{OnlySlides}

\ifslides
{
\setbeamercolor{background canvas}{bg=}
\includepdf[pages=2-10]{tsp-solved.pdf}
}
\fi


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}






%-------------------------------------------------------------------------
\begin{frame}{}

\end{frame}


